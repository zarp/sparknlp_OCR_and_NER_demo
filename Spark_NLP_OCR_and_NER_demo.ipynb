{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "We will use Spark NLP to perform OCR and then NER (named entity extraction) on public PDF documents pulled from the web. In particular - we will build a Spark NLP pipeline that processes a set of PDF documents, OCR's them and pull entities like person, location, and organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete for  https://www.cdc.gov/nchhstp/stateprofiles/pdf/Arizona_profile.pdf\n",
      "Download complete for  https://www.nrdc.org/sites/default/files/ClimateWaterFS_PhoenixAZ.pdf\n",
      "Download complete for  https://www.azcc.gov/Divisions/Corporations/Ten-Steps-to-Starting-a-Business-in-Arizona.pdf\n"
     ]
    }
   ],
   "source": [
    "#PDFs that will be downloaded and used as inputs for our OCR + NER pipeline\n",
    "filenames = ['https://www.cdc.gov/nchhstp/stateprofiles/pdf/Arizona_profile.pdf',\n",
    "             'https://www.nrdc.org/sites/default/files/ClimateWaterFS_PhoenixAZ.pdf',\n",
    "             'https://www.azcc.gov/Divisions/Corporations/Ten-Steps-to-Starting-a-Business-in-Arizona.pdf'\n",
    "            ]\n",
    "\n",
    "files_for_ocr = []\n",
    "\n",
    "import urllib.request\n",
    "for ind, fname in enumerate(filenames):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(fname, 'testfile_' + str(ind) + '.pdf')\n",
    "        print('Download complete for ', fname)\n",
    "        files_for_ocr.append('testfile_' + str(ind) + '.pdf')\n",
    "    except:\n",
    "        print('Failed to download file ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "spark = sparknlp.start(include_ocr=True)\n",
    "model = PretrainedPipeline('explain_document_dl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on file:  testfile_0.pdf\n",
      "People:  {'\\uf0b7'}\n",
      "Organizations:  {'Initiatives', 'P&S', 'Reported', 'Health', 'National', 'Arizona', 'Profile', 'Centers', 'State', 'CDC', 'Control', 'Center', 'Prevention', 'School', '\\uf0b7', 'Disease', 'Supported', 'CS2382532', 'TB', 'Ranked', 'health', 'for', 'HIV/AIDS', 'Information', 'More', 'Program'}\n",
      "Locations:  {'States', 'County', 'Arizona', 'U.S.', 'Maricopa', 'United'}\n",
      "\n",
      "Working on file:  testfile_1.pdf\n",
      "People:  {'Michelle', 'Mehta'}\n",
      "Organizations:  {'l_', 'Becoming', 'Phoenix’s', 'For', 'Change', 'Resilient', 'and', 'Impacts', 'Climate', 'Southwest', 'Council', 'Network', 'H', 'PDF', 'NRDC', '“', 'Arizona-Identifying', '©', 'Resources', 'Defense', 'of', 'Natural', 'Phoenix', 'The', 'More', 'CAP'}\n",
      "Locations:  {'Central', 'Project', 'Granite', 'Underground', 'Storage', 'Colorado', 'Sonoran', 'Reef', 'States', 'Arizona', 'Phoenix', 'Desert', 'United', 'Verde', 'River', 'Situated', 'Salt'}\n",
      "\n",
      "Working on file:  testfile_2.pdf\n",
      "People:  set()\n",
      "Organizations:  {'Incorporation', 'Services', 'Revenue', 'the', 'Service', 'Authority', 'EIN', 'DIVISION', 'Submit', 'OR', 'CORPORATION', 'TIN', 'Arizona', 'CORPORATIONS', 'State', 'Commission', 'Division', 'LLCs', 'Articles', 'IRS', 'LLC', 'Google', 'ADOR', 'Internal', 'Commerce', 'Organization', 'Check', 'State’s', '\\uf0b7', 'COMMISSION', 'Business', 'CITY', 'of', '–', 'Small', 'Corporation', 'A', 'A.C.C.', 'Department', 'ARIZONA', 'FEDERAL', 'Corporations'}\n",
      "Locations:  {'Street', 'Washington', 'West', 'Arizona', 'Phoenix', 'A.C.C.', 'State', 'ARIZONA'}\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.ocr import OcrHelper\n",
    "\n",
    "for cur_file in files_for_ocr:\n",
    "    print('\\nWorking on file: ', cur_file)\n",
    "    data = OcrHelper().createDataset(spark, cur_file)\n",
    "\n",
    "    people, locs, orgs = set(), set(), set() #'I-PER', 'I-LOC', 'I-ORG' \n",
    "    for row in data.collect():\n",
    "        result = model.annotate(row['text'], 'text')\n",
    "        ner_outputs = list(zip(result['token'], result['ner']))\n",
    "\n",
    "        for entry in ner_outputs:\n",
    "            if entry[1] == 'I-PER':\n",
    "                people.add(entry[0])\n",
    "            elif entry[1] == 'I-ORG':\n",
    "                orgs.add(entry[0])\n",
    "            elif entry[1] == 'I-LOC':\n",
    "                locs.add(entry[0])\n",
    "\n",
    "    print('People: ', people)\n",
    "    print('Organizations: ', orgs)\n",
    "    print('Locations: ', locs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
