{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark NLP: Part of Speech (POS) and Named Entity Recognition (NER) demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the given dataset using spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Reuters historica...|\n",
      "|Following are som...|\n",
      "|1714 - The Treaty...|\n",
      "|1812 - Russian ar...|\n",
      "|Napoleon entered ...|\n",
      "|1822 - Brazil pro...|\n",
      "|As Liberal prime ...|\n",
      "|1860 - Giuseppe G...|\n",
      "|1901 - In China ,...|\n",
      "|1909 - Elia Kazan...|\n",
      "|1913 - Sir Anthon...|\n",
      "|He succeeded to t...|\n",
      "|1969 - Scottish m...|\n",
      "|Four years later ...|\n",
      "|1986 - Bishop Des...|\n",
      "|He was the first ...|\n",
      "|1990 - The United...|\n",
      "|He won acclaim fo...|\n",
      "|1993 - Six former...|\n",
      "|1994 - The Stars ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"spark_nlp_demo\")\\\n",
    "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.0.9\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = spark.read.parquet('sample_text.parquet')\n",
    "\n",
    "data.printSchema()\n",
    "data.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create a Spark ML Pipeline using pretrained english  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.embeddings import *\n",
    "\n",
    "my_DocumentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "    \n",
    "my_SentenceDetector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\") \\\n",
    "    .setUseAbbreviations(True)\n",
    "\n",
    "my_Tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "my_WordEmbModel =  WordEmbeddingsModel.pretrained('glove_100d')\n",
    "\n",
    "my_PosTagger = PerceptronModel.pretrained('pos_anc') \\\n",
    "  .setInputCols([\"sentence\", \"token\"])\n",
    "\n",
    "my_NerCrfModel = NerCrfModel.pretrained('ner_crf')\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    my_DocumentAssembler,\n",
    "    my_SentenceDetector,\n",
    "    my_Tokenizer,\n",
    "    my_WordEmbModel,\n",
    "    my_PosTagger,\n",
    "    my_NerCrfModel]) \n",
    "\n",
    "model = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the transformed DataFrame showing only the POS column and the NER column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 pos|                 ner|\n",
      "+--------------------+--------------------+\n",
      "|[NNP, JJ, NN, -, ...|[I-ORG, O, O, O, ...|\n",
      "|[VBG, VBP, DT, IN...|[O, O, O, O, O, O...|\n",
      "|[CD, :, DT, NNP, ...|[O, O, O, I-ORG, ...|\n",
      "|[CD, :, JJ, NN, I...|[O, O, I-MISC, O,...|\n",
      "|[NNP, VBD, NNP, D...|[I-PER, O, I-LOC,...|\n",
      "|[CD, :, NNP, VBD,...|[O, O, I-LOC, O, ...|\n",
      "|[IN, NNP, JJ, NN,...|[O, I-MISC, O, O,...|\n",
      "|[CD, :, NNP, NNP,...|[O, O, I-PER, I-P...|\n",
      "|[CD, :, IN, NNP, ...|[O, O, O, I-LOC, ...|\n",
      "|[CD, :, NNP, NNP,...|[O, O, I-PER, I-P...|\n",
      "|[CD, :, NNP, NNP,...|[O, O, O, I-PER, ...|\n",
      "|[PRP, VBD, TO, DT...|[O, O, O, O, O, O...|\n",
      "|[CD, :, NNP, NN, ...|[O, O, I-MISC, O,...|\n",
      "|[CD, NNS, RB, ,, ...|[O, O, O, O, O, O...|\n",
      "|[CD, :, NNP, NNP,...|[O, O, O, I-PER, ...|\n",
      "|[PRP, VBD, DT, JJ...|[O, O, O, O, O, O...|\n",
      "|[CD, :, DT, NNP, ...|[O, O, O, I-LOC, ...|\n",
      "|[PRP, VBD, NN, IN...|[O, O, O, O, O, O...|\n",
      "|[CD, :, CD, JJ, N...|[O, O, O, O, I-MI...|\n",
      "|[CD, :, DT, NNP, ...|[O, O, O, I-ORG, ...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "pos_and_ner = model.select([col(\"pos.result\").alias(\"pos\"), col(\"ner.result\").alias(\"ner\")])\n",
    "pos_and_ner.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  As a toy example, we will show that entities classified as nouns (POS tag starts with \"N\") are much more likely to have NER tag other than O compared to the other parts of speech, e.g. verbs or adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+-------------------+-----------------------+\n",
      "|sum(pos_noun_ner_O)|sum(pos_noun_ner_not_O)|sum(pos_rest_ner_O)|sum(pos_rest_ner_not_O)|\n",
      "+-------------------+-----------------------+-------------------+-----------------------+\n",
      "|               5069|                   3896|              16901|                    241|\n",
      "+-------------------+-----------------------+-------------------+-----------------------+\n",
      "\n",
      "Fraction of nouns labeled as non-O by NER =  0.4345789180145008\n",
      "Fraction of all other POS labeled as non-O by NER =  0.01405903628514759\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def ner_count_in_pos_group(pos_is_noun, ner_is_O, pos_list, ner_list):\n",
    "    selected_pos_inds =  [ind for ind, el in enumerate(pos_list) if (el[0] == \"N\") == pos_is_noun]\n",
    "    return len([el for ind, el in enumerate(ner_list) if (ind in selected_pos_inds) and ((el == \"O\") == ner_is_O)])\n",
    "\n",
    "pos_noun_ner_O = udf(lambda x,y: ner_count_in_pos_group(True, True, x, y), IntegerType())\n",
    "pos_noun_ner_not_O = udf(lambda x,y: ner_count_in_pos_group(True, False, x, y), IntegerType())\n",
    "pos_rest_ner_O = udf(lambda x,y: ner_count_in_pos_group(False, True, x, y), IntegerType())\n",
    "pos_rest_ner_not_O = udf(lambda x,y: ner_count_in_pos_group(False, False, x, y), IntegerType())\n",
    "\n",
    "summary = pos_and_ner.select(\"pos\", \"ner\", \n",
    "                 pos_noun_ner_O('pos', 'ner').alias('pos_noun_ner_O'),\n",
    "                 pos_noun_ner_not_O('pos', 'ner').alias('pos_noun_ner_not_O'),\n",
    "                 pos_rest_ner_O('pos', 'ner').alias('pos_rest_ner_O'),\n",
    "                 pos_rest_ner_not_O('pos', 'ner').alias('pos_rest_ner_not_O'))\n",
    "\n",
    "summary = summary.groupBy().sum()\n",
    "summary.show()\n",
    "\n",
    "sums = summary.collect()[0][:]  #('pos_noun_ner_O', 'pos_noun_ner_not_O', 'pos_rest_ner_O', 'pos_rest_ner_not_O')\n",
    "\n",
    "print('Fraction of nouns labeled as non-O by NER = ', sums[1] / (sums[0] + sums[1]))\n",
    "print('Fraction of all other POS labeled as non-O by NER = ', sums[3] / (sums[2] + sums[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
